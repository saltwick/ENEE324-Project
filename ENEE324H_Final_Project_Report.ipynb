{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ENEE324H-Final-Project-Report",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssaltwick/ENEE324-Project/blob/master/ENEE324H_Final_Project_Report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pSqIAPEHDcG",
        "colab_type": "text"
      },
      "source": [
        "# ENEE324H Final Project\n",
        "## Sam Saltwick & Frank Lopez\n",
        "\n",
        "### Introduction\n",
        "Our project seeks to cluster basketball players into their respective positions based on a select grouping of their per game average statistics. \n",
        "\n",
        "To see the project in action, check out 'Try It Out' section at the bottom."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkfYepC99EMa",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "This section contains setup for the code to run, including package imports, data importing, and an enumeration definition."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7PXGZxZ3bSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.stats as stat\n",
        "import math\n",
        "import pandas as pd\n",
        "from enum import Enum\n",
        "from mpl_toolkits import mplot3d\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "\n",
        "class Position(Enum):\n",
        "  PG = 0\n",
        "  SG = 1\n",
        "  SF = 2\n",
        "  PF = 3\n",
        "  C = 4\n",
        "  \n",
        "pos_names = {\n",
        "    Position.PG : \"PG\",\n",
        "    Position.SG : \"SG\",\n",
        "    Position.SF : \"SF\",\n",
        "    Position.PF : \"PF\",\n",
        "    Position.C : \"C\",\n",
        "}\n",
        "\n",
        "# Data is hosted on a github repo\n",
        "pg_url = 'https://raw.githubusercontent.com/ssaltwick/ENEE324-Project/master/data/Data%20-%20PG-clean.csv'\n",
        "sg_url = 'https://raw.githubusercontent.com/ssaltwick/ENEE324-Project/master/data/Data%20-%20SG-clean.csv'\n",
        "sf_url = 'https://raw.githubusercontent.com/ssaltwick/ENEE324-Project/master/data/Data%20-%20SF-clean.csv'\n",
        "pf_url = 'https://raw.githubusercontent.com/ssaltwick/ENEE324-Project/master/data/Data%20-%20PF-clean.csv'\n",
        "c_url = 'https://raw.githubusercontent.com/ssaltwick/ENEE324-Project/master/data/Data%20-%20C-Clean.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/ssaltwick/ENEE324-Project/master/data/Data%20-%20Test-Clean.csv'\n",
        "\n",
        "urls = {\n",
        "    Position.PG : pg_url,\n",
        "    Position.SG : sg_url,\n",
        "    Position.SF : sf_url,\n",
        "    Position.PF : pf_url,\n",
        "    Position.C : c_url\n",
        "}\n",
        "\n",
        "# Get test data\n",
        "test_data = pd.read_csv(test_url).dropna()\n",
        "test_data['Player'] = test_data['Player'].str.split('\\\\').str[0]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX5zgqxhHxCa",
        "colab_type": "text"
      },
      "source": [
        "### Data \n",
        "\n",
        "For this project we used accumulated NBA player statistics from the year 2014 up until the previous season (2018-2019 season). We gathered the data from [basketball-reference.com](https://www.basketball-reference.com/). Our preliminary data included 11 stats (FG% 3PA\t3P%\t2P%\tFT%\tORB\tTRB\tAST\tSTL\tBLK\tPTS) that through exploratory data analysis we reduced to fewer statistics. This process is described in our approach section. Our raw data can be found [here](https://docs.google.com/spreadsheets/d/1-6pwAv2Xz1BJTd7Pb0yBK6wmOlAbqYu_X7MPdkgKyEs/edit?usp=sharing).\n",
        "\n",
        "We used the data from 2014-2018 to train our model for each position and then tested our model on the most player's recent season (2018-2019). To make sure the data we used was statistically significant, we only used players that played 30 games or more, while averaging at least 10 minutes played per game.\n",
        "\n",
        "\n",
        "### Approach\n",
        "\n",
        "In order to cluster our players into their positions, we used Bayes law to estimate the quantity P(Position | Player). Here we define a position as one of the 5 positions in basketball (PG, SG, SF, PF, C) and a player as a series of player statistics representing a player in the 2018-2019 season. For each player, we calculate this quantity 5 times, once for each position. Then with 5 values for each player, we take the maximum value and select the associated position as our player's position.\n",
        "\n",
        "Our application of Bayes law resulted in the calculation P(Player | Position) * P(Position). We chose to ignore the summation in the denominator as we are comparing these values against each other and selecting the maximum. Since we are comparing the values, we do not need them to sum to 1, so we do not need to calculate this denominator. The P(Player) value, or the prior, was simply calculated as (# players in position / # players). Our likelihood function (P(Player | Position)) was assumed to be a Gaussian distribution. This assumption is based on the fact that each statistic was found to be close to normally distributed across positions. According to Bayes Law, the product of our prior and our likelihood function gives us a value proportional to P(Position | Player). \n",
        "\n",
        "For our likelihood function, we used an N dimensional Gaussian distribution where the mean and covariance were found as the mean and covariance of our dataset, accumulated over all years that we used. The dimension of this function (N) changes based on the number of statistics used to develop the model. This process is discussed down below in regards to our two stage process.\n",
        "\n",
        "Initially, we calculated the likelihood function of each player for each position and multiplied it by the probablity of that position. This gave us a value for each position for each player which we used to cluster the players into positions. Preliminary testing found that the best statistics to use for this method were 3-point attempts, 3-point percentage, 2-point percentage, and blocks. While we had 11 total statistics to utilize, adding more statistics generally led to poor results. Certain statistics had stronger effects on the accuracy thatn others, such as points. When the points per game statistic was introduced into the model, it dropped the accuracy significantly every time. After running our test data through this model, we found an accuracy of **41.01%**. Seeking to improve this accuracy, we thought of a different way to cluster our data.\n",
        "\n",
        "Our final approach includes two stages. The first stage clusters the data into 3 bins: [PG,SF], [SG, PF] and [C]. These bins were determined through iterative testing, calculating the accuracy of all 51 partitions of the list of positions and finding the best one. For each partition of the list, we also found the best combination of statistics to use. Since we found that using all of the statistics that we prepared usually resulted in a worse accuracy, we tested each number of statistics and determined that the best combination for stage 1 was to use 3-points attempted, 2 point percentage, assists, free throw percentage, steals, blocks, and offensive rebounds (All per game averages). Using this combination of 7 stats, we cluster each point in the test data into one of the three bins. At this point, we were able to get up to **59.27%** accuracy.The three bins were then entered into stage two of our algorithm.\n",
        "\n",
        "Stage two works similarly to stage 1, except it started with our three bins and resulted in a cluster for each position. We reused the process from stage 1 to determine the optimal set of statistics to use with stage 2, for each bin. For the first bin, [PG, SF] we found the optimal statistics to use to be 3-point percentage, offensive rebounds, and total rebounds. For the second bin, [SG. PF], the best statistics to use were 2-point percentage and total rebounds. Since our last bin only contains Centers, it does not need to run through stage 2.\n",
        "\n",
        "After stage two we are left with 5 values for each player, proportional to the probability that each player is the corresponding position. The position associated with the maximum value is chosen as that player's position. With this two stage method, we found a total accuracy of **48.31%**.\n",
        "\n",
        "Our accuracy calculation is done by measuring the number of players that we clustered correctly and dividing it by the total number of players clustered. \n",
        "\n",
        "### Results\n",
        "\n",
        "As previously discussed, our final process resulted in an overall accuracy of **48.31%** using the optimal combination of two-stage clustering and selected statistics. Our original method, a single staged cluster directly into postions, resulted in only 41.01% accuracy. Our improved method increased the accuracy of the model by over 7%.\n",
        "\n",
        "While our accuracy is low, we do believe that our clustering model works relatively well. Considering that there are 5 different options for position, the expected percent correct would be 20%. Our model does much better than this, successfully clustering almost 2.5 times more players than a stochastic method would. Because of this comparision, we believe that our clustering process can successfully work to better determine a player from their statistics. \n",
        "\n",
        "### Further Work\n",
        "\n",
        "Many further investigations into this topic are possible. The weakest point of the model is the assumption that the statistics for each distribution would be fairly normal. While this did appear to be true, plotting 3 statistics together with a Gaussian ellipsoid reveals that many players still fall outside of the models predicted range. Developing a different likelihood function through other statistic methods could definitely improve the accuracy of our model.\n",
        "\n",
        "Another extension of this would would be extending our training data to include more NBA seasons. We only included 4 seasons of training data, but including more (10+ seasons) could improve our accuracy. One reason this may not be the case is that the game of basketball has drastically changed over the years. As the game changes, the roles of each position changes with it, which would skew our results and over many years could result in an underfitted model. \n",
        "\n",
        "Alternatively we could test our data on previous seasons to examine how well our position models hold up for years before they were trained on. We could also introduce players from leagues other than the NBA (NCAAM, NCAAW, NBA G-League) to evaluate if our models for positions fit players across all forms of basketball.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8aqt4cNEXGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "  Evaluates a player against a position's likelihood.\n",
        "  params: positon = Position Enum\n",
        "          player = numpy array of stats\n",
        "\n",
        "\"\"\"\n",
        "def evaluate_likelihood(position, player, avgs, covs, prior):\n",
        "  mu = avgs[position]\n",
        "  sig = covs[position]\n",
        "  \n",
        "  p = (math.sqrt(2*math.pi)) ** 3\n",
        "  c = 1 / (p * math.sqrt(np.linalg.det(sig)))\n",
        "\n",
        "  \n",
        "  t = np.dot(np.transpose(player-mu), np.dot(sig, (player-mu)))\n",
        "  \n",
        "  \n",
        "  return c * math.exp(-0.5 * t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6sia2sREXK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def guess_position(player, avgs, covs, prior, pos):\n",
        "  positions = {}\n",
        "  \n",
        "  for p in pos:\n",
        "    positions[p] = evaluate_likelihood(p, player, avgs, covs, prior) * prior[p]\n",
        "  \n",
        "  v = list(positions.values())\n",
        "  k = list(positions.keys())\n",
        "  return k[v.index(max(v))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swZTYPg-EMpU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stage1(player, round1_stats, labels):\n",
        "  \n",
        "\n",
        "\n",
        "  \n",
        "  positions = [Position.PG, Position.SG, Position.SF, Position.PF, Position.C]\n",
        "  \n",
        "\n",
        "  bins = {}\n",
        "  \n",
        "  for l in labels:\n",
        "    tmp = [pos_names[x] for x in l]\n",
        "    bins[''.join(tmp)] = []\n",
        "    \n",
        "  \n",
        "  data = {}\n",
        "  for p in positions:\n",
        "    data[p] = pd.read_csv(urls[p]).dropna()[round1_stats]  \n",
        "\n",
        "\n",
        "\n",
        "  total_players = 0\n",
        "  for p in positions:\n",
        "    total_players += data[p].shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  # Defines an array of priors (each position's percentage of players)\n",
        "  # TODO: Update with actual priors),\n",
        "\n",
        "  prior = {}\n",
        "  avgs = {}\n",
        "  covs = {}\n",
        "\n",
        "\n",
        "  # TODO: Generate actual MEAN and COV for each position\n",
        "\n",
        "  for p in positions:\n",
        "    prior[p] = data[p].shape[0] / total_players\n",
        "\n",
        "  for p in positions:\n",
        "    avgs[p] = data[p].mean(0).to_numpy()\n",
        "    covs[p] = data[p].cov().to_numpy()\n",
        "\n",
        "  \n",
        "  guess = guess_position(player[:,0], avgs, covs, prior, positions)\n",
        "    \n",
        "    \n",
        "  for l in labels:\n",
        "    tmp = [pos_names[x] for x in l]\n",
        "    k = ''.join(tmp)\n",
        "    if guess in l:\n",
        "      bins[k].append(player)\n",
        "       \n",
        "  restult = \"\"     \n",
        "  for k in bins.keys():\n",
        "    if bins[k]:\n",
        "      result = k\n",
        "      \n",
        "  return result\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVr7Eb_DEOfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stage2(labels, stats, test_player):\n",
        "  \n",
        "  positions = [Position.PG, Position.SG, Position.SF, Position.PF, Position.C]\n",
        "  \n",
        "  test_player = test_player[stats].to_numpy()\n",
        "  \n",
        "  bins = {}\n",
        "  for p in labels:\n",
        "    bins[p] = []\n",
        "  \n",
        "  pos_names = {\n",
        "      Position.PG : \"PG\",\n",
        "      Position.SG : \"SG\",\n",
        "      Position.SF : \"SF\",\n",
        "      Position.PF : \"PF\",\n",
        "      Position.C : \"C\",\n",
        "  }\n",
        "  \n",
        "  \n",
        "  data = {}\n",
        "  for p in positions:\n",
        "    data[p] = pd.read_csv(urls[p]).dropna()[stats]  \n",
        "\n",
        "\n",
        "  total_players = 0\n",
        "  for p in positions:\n",
        "    total_players += data[p].shape[0]\n",
        "\n",
        "\n",
        "\n",
        "  # Defines an array of priors (each position's percentage of players)\n",
        "  # TODO: Update with actual priors),\n",
        "\n",
        "  prior = {}\n",
        "  avgs = {}\n",
        "  covs = {}\n",
        "\n",
        "\n",
        "  # TODO: Generate actual MEAN and COV for each position\n",
        "\n",
        "\n",
        "  for p in positions:\n",
        "    total_players += data[p].shape[0]\n",
        "\n",
        "  for p in positions:\n",
        "    prior[p] = data[p].shape[0] / total_players\n",
        "\n",
        "  for p in positions:\n",
        "    avgs[p] = data[p].mean(0).to_numpy()\n",
        "    covs[p] = data[p].cov().to_numpy()\n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "     \n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  guess = guess_position(test_player.reshape(len(stats),), avgs, covs, prior, labels)\n",
        "\n",
        "  bins[guess].append(test_player)\n",
        "  \n",
        "\n",
        "  \n",
        "  return pos_names[guess]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iNYjwxR-E9g",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model\n",
        "Evaluates the model given a player"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bcoTrr1G-rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_model(selected_player, test_data):\n",
        "  # Retrieve selected player from test data\n",
        "\n",
        "  test_player = test_data.loc[test_data['Player'] == selected_player]\n",
        "  \n",
        "  test_pos = test_player['Pos'].to_string().split()[1]\n",
        "  status = 0\n",
        "\n",
        "  # print(\"Here is %s's stats for the 2018-2019 season\" % selected_player)\n",
        "  # print(test_player)\n",
        "  \n",
        "  \n",
        "  # Stage 1 - cluster into [PG, SF], [SG, PF], [C] based on \n",
        "  # 3PA, 2P%, AST, FT%, STL, BLK, ORB\n",
        "  s1_stats = ['3PA', '2P%', 'AST', 'FT%', 'STL', 'BLK', 'ORB']\n",
        "  groups = [[Position.PG, Position.SF],[Position.SG, Position.PF],[Position.C]]\n",
        "  s1_result = stage1(np.transpose(test_player[s1_stats].to_numpy()), s1_stats, groups)\n",
        "  \n",
        "  s1_worked = False\n",
        "  if test_pos in s1_result:\n",
        "    print(\"Stage 1 correctly categorized %s as %s\" % (selected_player, s1_result))\n",
        "    s1_worked = True\n",
        "\n",
        "  # Stage 2 - Take whichever bin they were placed into and split based on \n",
        "  # [3P%, ORB, TRB], [2P%, TRB], [3PA]\n",
        "  \n",
        "  s2_stats = {\n",
        "      \"PGSF\" : ['3P%', 'ORB', 'TRB'],\n",
        "      \"SGPF\" : ['2P%', 'TRB'],\n",
        "      \"C\" : ['3PA']\n",
        "  }\n",
        "\n",
        "  s2_result = \"Error\"\n",
        "  if s1_result == \"PGSF\":\n",
        "    s2_result = stage2([Position.PG, Position.SF], s2_stats[\"PGSF\"], test_player)\n",
        "  elif s1_result == \"SGPF\":\n",
        "    s2_result = stage2([Position.SG, Position.PF], s2_stats[\"SGPF\"], test_player)\n",
        "  else:\n",
        "    s2_result = 'C'\n",
        "\n",
        "  if s2_result == test_pos:\n",
        "    print(\"Stage 2 correctly categorized %s as a %s\" % (selected_player, s2_result))\n",
        "    status = 1\n",
        "  else:\n",
        "    print(\"%s was categorized as a %s in stage 2 but is actually a %s. Try another player.\" %(selected_player, s2_result, test_pos))\n",
        "    \n",
        "  return status\n",
        "  \n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrOAQY_U9nPt",
        "colab_type": "text"
      },
      "source": [
        "### Try it Out\n",
        "To test out our model, select an NBA player from the dropdown below to see if it guesses the correct position."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9UXvu872V3v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "cellView": "both",
        "outputId": "8bc2a462-dd17-40d1-8645-8aaf42bd33c4"
      },
      "source": [
        "selected_player = \"James Harden\" #@param {type:\"string\"}\n",
        "\n",
        "_ = run_model(selected_player, test_data)\n",
        "# all_names = test_data['Player']\n",
        "# sample = all_names.shape[0]\n",
        "\n",
        "# correct = 0;\n",
        "# for n in all_names:\n",
        "#   correct += run_model(n, test_data)\n",
        "\n",
        "# print(correct / sample)\n",
        "\n",
        "\n"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "James Harden was categorized as a C in stage 2 but is actually a PG. Try another player.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}